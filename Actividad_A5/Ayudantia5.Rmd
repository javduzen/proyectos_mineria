---
title: "Ayudantia 5 Clusters"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Actividad Ayudantia 5

Realizar análisis de clustering (K-means, incluye preprocesamiento de la data) e índices de evaluación para el archivo "sandwiches.csv" tomando las columnas de nota y precio. Hacer análisis para diferentes K y/o medidas de distancia para que vean cómo se comporta el clustering (En caso de tener algún problema con ese csv, pueden utilizar el csv de Pokémon también para la actividad)


# Algoritmo de clustering base:

## K-Medias

Para el análisis de clusters vamos a analizar la data de  “pokemon.csv” que contiene la información de los pokemones de 7 de sus generaciones, echaremos un vistazo a las variables presentes.
```{r load data}
library(tidyverse)


data_pok  <- read.csv(file='C:/Users/Javiera/Desktop/RAMOS 2021/Minería/proyectos_mineria/Actividad_A5/sanguchez.csv',sep=";")

head(data_pok)

summary(data_pok)

```

Para clusterizar vamos a seleccionar las variables Nota y precio

Antes de clusterizar debemos preparar la data:

Pasar el precio a numero

Eliminar datos faltantes (NAs).

Escalar la data

```{r}
data <- subset(data_pok, select = -c(texto, url, Local, Direccion, Ingredientes))
#summary(data)
#head(data)

data$Precio <- as.numeric(gsub('[$.]', '', data$Precio))
#head(data)
#summary(data)
data <- data[complete.cases(data), ]
summary(data)
```
Ya con la columna precios limpia podemos proceder a escalar los datos y luego aplicar el algoritmo
```{r}
numdata <- data[, colnames(data) %in% c("Precio","nota")]

escal_data = scale(numdata) %>% as_tibble()

escal_data %>% summary()
```
# Analisis Cluster K = 10
```{r}
modelo_kmeans <- kmeans(escal_data, centers = 10)
modelo_kmeans2 <- kmeans(numdata, centers = 10)

# creo la variable cluster en la tabla escal_data_pokda
escal_data$clus <- modelo_kmeans$cluster %>% as.factor()
numdata$clus <- modelo_kmeans2$cluster %>% as.factor()

ggplot(escal_data, aes(Precio, nota, color=clus)) +
  geom_point(alpha=0.5, show.legend = T) +
  theme_bw()
```
```{r}
ggplot(numdata, aes(Precio, nota, color=clus)) +
  geom_point(alpha=0.5, show.legend = T) +
  theme_bw()
```

```{r}
info_clus <- modelo_kmeans$centers
info_clus2 <- modelo_kmeans2$centers

info_clus
info_clus2
```
# Evolución suma de cuadrados intra-cluster en la medida que aumentamos el numero de k
```{r}
SSinterior <- numeric(30)

for(k in 1:30){
  modelo <- kmeans(escal_data, centers = k)
  SSinterior[k] <- modelo$tot.withinss
}

plot(SSinterior)
```

# Evaluacion
## Inspeccion visual
```{r}
escal_data$clus <- as.numeric(escal_data$clus)
numdata$clus <- as.numeric(numdata$clus)

# uso distancia euclidiana
tempDist <- dist(escal_data) %>% as.matrix()

#reordeno filas y columnas en base al cluster obtenido
index <- sort(modelo_kmeans$cluster, index.return=TRUE)
tempDist <- tempDist[index$ix,index$ix]
rownames(tempDist) <- c(1:nrow(escal_data))
colnames(tempDist) <- c(1:nrow(escal_data))

image(tempDist)
```
# Estadistico de Hopkins.
```{r}
library(factoextra)
res <- get_clust_tendency(escal_data, n = 30, graph = FALSE)
res2 <- get_clust_tendency(numdata, n = 30, graph = FALSE)

print(res)
```
# Indice de correlacion
```{r}
tempMatrix <- matrix(0, nrow = nrow(numdata), ncol = nrow(numdata))
tempMatrix[which(index$x==1), which(index$x==1)]  <- 1
tempMatrix[which(index$x==2), which(index$x==2)]  <- 1
tempMatrix[which(index$x==3), which(index$x==3)]  <- 1
tempMatrix[which(index$x==4), which(index$x==4)]  <- 1
tempMatrix[which(index$x==5), which(index$x==5)]  <- 1
tempMatrix[which(index$x==6), which(index$x==6)]  <- 1
tempMatrix[which(index$x==7), which(index$x==7)]  <- 1
tempMatrix[which(index$x==8), which(index$x==8)]  <- 1
tempMatrix[which(index$x==9), which(index$x==9)]  <- 1
tempMatrix[which(index$x==10), which(index$x==10)] <- 1

#construyo matriz de disimilitud
tempDist2 <- 1/(1+tempDist)

#Calcula correlacion 
cor <- cor(tempMatrix[upper.tri(tempMatrix)],tempDist2[upper.tri(tempDist2)])

print(cor)
```
# Indice de cohesión y el de separación
```{r}
library(flexclust)
withinCluster <- numeric(10)
for (i in 1:10){
  tempdata <- escal_data[which(modelo_kmeans$cluster == i),]
  withinCluster[i] <- sum(dist2(tempdata,colMeans(tempdata))^2)
}
cohesion = sum(withinCluster)
#es equivalente a model$tot.withinss en k-means
print(c(cohesion, modelo_kmeans$tot.withinss))

```
# Coeficiente de silueta
```{r}
library(cluster)

coefSil <- silhouette(modelo_kmeans$cluster,dist(escal_data))
summary(coefSil)
fviz_silhouette(coefSil) + coord_flip()

```
## Utilizamos el coeficiente de silueta para encontrar el mejor valor de K
```{r}
coefSil=numeric(30)
for (k in 2:30){
  modelo <- kmeans(escal_data, centers = k)
  temp <- silhouette(modelo$cluster,dist(escal_data))
  coefSil[k] <- mean(temp[,3])
}
tempDF=data.frame(CS=coefSil,K=c(1:30))

ggplot(tempDF, aes(x=K, y=CS)) + 
  geom_line() +
  scale_x_continuous(breaks=c(1:30))
```
# 2do Análisis Cluster
En este nuevo caso con K = 4

```{r}
numdata2 <- data[, colnames(data) %in% c("Precio", "nota")]
escal_data2 = scale(numdata2) %>% as_tibble()

modelo_kmean <- kmeans(escal_data2, centers = 4)
modelo_kmean2 <- kmeans(numdata2, centers = 4)

# creo la variable cluster en la tabla escal_data_pokda
escal_data2$clus2 <- modelo_kmean$cluster %>% as.factor()
numdata2$clus2 <- modelo_kmean2$cluster %>% as.factor()

ggplot(escal_data2, aes(Precio, nota, color=clus2)) +
  geom_point(alpha=0.5, show.legend = T) +
  theme_bw()
```
```{r}
ggplot(numdata2, aes(Precio, nota, color=clus2)) +
  geom_point(alpha=0.5, show.legend = T) +
  theme_bw()
```
```{r}
info_clusters <- modelo_kmean$centers
info_clusters2 <- modelo_kmean2$centers

info_clusters
info_clusters2
```
# Evaluacion
## Inspeccion visual
```{r}
escal_data2$clus <- as.numeric(escal_data2$clus2)
numdata2$clus <- as.numeric(numdata2$clus2)

# uso distancia euclidiana
tempDist_2 <- dist(escal_data2) %>% as.matrix()

#reordeno filas y columnas en base al cluster obtenido
index <- sort(modelo_kmean$cluster, index.return=TRUE)
tempDist_2 <- tempDist_2[index$ix,index$ix]
rownames(tempDist_2) <- c(1:nrow(data))
colnames(tempDist_2) <- c(1:nrow(data))

image(tempDist_2)
```
## Estadistico de hopkins
```{r}
library(factoextra)

escal_data2$clus2 <- NULL
numdata2$clus2 <- NULL

#Calcula el hopkins statistic 
res_1 <- get_clust_tendency(escal_data2, n = 30, graph = FALSE)
res_2 <- get_clust_tendency(numdata2, n = 30, graph = FALSE)

print(res_1)
```
```{r}
print(res_2)
```
## Indice de correlacion
```{r}
tempMatrix2 <- matrix(0, nrow = nrow(escal_data2), ncol = nrow(escal_data2))
tempMatrix2[which(index$x==1), which(index$x==1)]  <- 1
tempMatrix2[which(index$x==2), which(index$x==2)]  <- 1
tempMatrix2[which(index$x==3), which(index$x==3)]  <- 1
tempMatrix2[which(index$x==4), which(index$x==4)]  <- 1
tempMatrix2[which(index$x==5), which(index$x==5)]  <- 1

#construyo matriz de disimilitud
tempDist_22 <- 1/(1+tempDist_2)

#Calcula correlacion 
cor2 <- cor(tempMatrix2[upper.tri(tempMatrix2)],tempDist_2[upper.tri(tempDist_2)])

print(cor2)
```

# Coeficiente de silueta
```{r}
library(cluster)

coefSil2 <- silhouette(modelo_kmean$cluster,dist(escal_data2))
summary(coefSil2)
fviz_silhouette(coefSil2) + coord_flip()
```


