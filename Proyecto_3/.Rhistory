data$elev_low <- NULL
out_distance <- filter(data, type == 0)
boxplot(out_distance$distance, horizontal = TRUE)
out_distance2 <- filter(data, type == 1)
boxplot(out_distance2$distance, horizontal = TRUE)
out_avspeed <- filter(data, type == 0)
boxplot(as.numeric(out_avspeed$average_speed), horizontal = TRUE)
out_avspeed2 <- filter(data, type == 1)
boxplot(as.numeric(out_avspeed2$average_speed), horizontal = TRUE)
#Como en mi notebook los modelos no corrian por la cantidad de datos, tuve que disminuirla
set.seed(123)
data_sample <- sample_n(data, 100000)
#data_sample2 <-data_sample[!(data_sample$type== 0 | data_sample$type== 1),]
data_split <- initial_split(data_sample, prop = 0.8)
train <- training(data_split)
test <- testing(data_split)
test$pred_0 <- NULL
str(train)
receta <-
recipe(type ~ ., data = train)
receta
modelo_trees <-
decision_tree(tree_depth = 5, min_n = 10) %>%
set_engine("rpart") %>%
set_mode("classification")
modelo_trees
library(tibble)
library(pROC)
fit_mod <- function(mod){
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train)
model_pred <-
predict(modelo_fit, test, type = "prob") %>%
bind_cols(test)
return(model_pred
%>%
roc_auc(truth = type, .pred_0))
}
fit_mod(modelo_trees)
library(naivebayes)
modelo_nb <-
naive_Bayes(smoothness = .8) %>%
set_engine("naivebayes")
fit_mod(modelo_nb)
#library(kknn)
#modelo_knn <-
# nearest_neighbor(neighbors = 6) %>%
#set_engine("kknn") %>%
#set_mode("classification")
#fit_mod(modelo_knn)
modelo_rl <-
logistic_reg() %>%
set_engine("glm")
fit_mod(modelo_rl)
library(rpart.plot)
type <- rpart(type~., data = train, method = "class")
rpart.plot(type)
library(rpart.plot)
pred_type <- predict(type, newdata = test, type = "class")
pred_type %>% as.data.frame() %>% head()
pred_type %>% as.data.frame() %>% tail()
test$predictedtype <- pred_type
pred_incom_roc <- predict(type, newdata = test, type = "prob")
pred_incom_roc %>% as.data.frame() %>% head()
cm <- confusionMatrix(table(test$type, test$predictedtype))
test$predictedtype <- as.factor(test$predictedtype)
table <- data.frame(confusionMatrix(test$type, test$predictedtype)$table)
print(cm)
plotTable <- table %>%
mutate(goodbad = ifelse(table$Prediction == table$Reference, "Good", "Bad")) %>%
group_by(Reference) %>%
mutate(prop = Freq/sum(Freq))
confusionMatrix <- ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 25, size = 8) +
scale_fill_manual(name = " ", values = c(Good = "#F0FF00", Bad = "#34495E")) +
scale_alpha(name = " ") +
theme_classic() +
xlim(rev(levels(table$Reference))) +
scale_y_discrete(name = "Predicted", limits = c("1","0")) +
scale_x_discrete(name = "Actual", position = "top") +
#theme(legend.position = " ") +
theme(text=element_text(size=25,  family="sans")) +
ggtitle("Confusion Matrix") +
theme(plot.title = element_text(size = 25, family="sans", face = "bold"))
confusionMatrix
pred_type_roc <- predict(type, newdata = test, type = "class")
pred_type_roc <- pred_type_roc %>% as.data.frame()
prob <- pred_type_roc$"1"
ROC <- roc(test$type,prob)
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(ggplot2)
library(tidyverse)
library(yardstick)
library(tidymodels)
library(discrim)
library(caret)
library(Hmisc)
library(patchwork)
library(naivebayes)
library(kknn)
library(rpart)
library(rpart.plot)
library(pROC)
data <- readRDS("C:/Users/Javiera/Desktop/RAMOS 2021/Minería/proyectos_mineria/Proyecto_3/endurance.rds")
data_copy1 <- data
head(data)
summary(data)
str(data)
head(unique(data[c("type")]))
head(unique(data[c("records")]))
unique(data[c("device_name")])
unique(data[c("has_heartrate")])
data$type <- mapvalues(data$type, from=c('Ride','EBikeRide'), to=c(0,0))
data$type <- mapvalues(data$type, from=c('Run','Walk', 'Hike'), to=c(1,1,1))
data$type <- as.factor(data$type)
str(data)
data[, c(6:9,13)] <- sapply(data[, c(6:9,13)], as.numeric)
data$start_date_local <- as.numeric(data$start_date_local)
data$device_name <- NULL
describe(data)
data$id <- NULL
data$athlete <- NULL
data$records <- NULL
data$has_heartrate <-
data$start_date_local <- NULL
#data$elev <- as.numeric(as.numeric(data$elev_high) - as.numeric(data$elev_low))
data$elev_high <- NULL
data$elev_low <- NULL
out_distance <- filter(data, type == 0)
boxplot(out_distance$distance, horizontal = TRUE)
out_distance2 <- filter(data, type == 1)
boxplot(out_distance2$distance, horizontal = TRUE)
out_avspeed <- filter(data, type == 0)
boxplot(as.numeric(out_avspeed$average_speed), horizontal = TRUE)
out_avspeed2 <- filter(data, type == 1)
boxplot(as.numeric(out_avspeed2$average_speed), horizontal = TRUE)
#Como en mi notebook los modelos no corrian por la cantidad de datos, tuve que disminuirla
set.seed(123)
data_sample <- sample_n(data, 100000)
#data_sample2 <-data_sample[!(data_sample$type== 0 | data_sample$type== 1),]
data_split <- initial_split(data_sample, prop = 0.8)
train <- training(data_split)
test <- testing(data_split)
test$pred_0 <- NULL
str(train)
receta <-
recipe(type ~ ., data = train)
receta
modelo_trees <-
decision_tree(tree_depth = 5, min_n = 10) %>%
set_engine("rpart") %>%
set_mode("classification")
modelo_trees
library(tibble)
library(pROC)
fit_mod <- function(mod){
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train)
model_pred <-
predict(modelo_fit, test, type = "prob") %>%
bind_cols(test)
return(model_pred
%>%
roc_auc(truth = type, .pred_0))
}
fit_mod(modelo_trees)
library(naivebayes)
modelo_nb <-
naive_Bayes(smoothness = .8) %>%
set_engine("naivebayes")
fit_mod(modelo_nb)
#library(kknn)
#modelo_knn <-
# nearest_neighbor(neighbors = 6) %>%
#set_engine("kknn") %>%
#set_mode("classification")
#fit_mod(modelo_knn)
modelo_rl <-
logistic_reg() %>%
set_engine("glm")
fit_mod(modelo_rl)
library(rpart.plot)
type <- rpart(type~., data = train, method = "class")
rpart.plot(type)
library(rpart.plot)
pred_type <- predict(type, newdata = test, type = "class")
pred_type %>% as.data.frame() %>% head()
pred_type %>% as.data.frame() %>% tail()
test$predictedtype <- pred_type
pred_type_roc <- predict(type, newdata = test, type = "prob")
pred_type_roc %>% as.data.frame() %>% head()
pred_type_roc <- pred_type_roc %>% as.data.frame()
prob <- pred_type_roc$"1"
cm <- confusionMatrix(table(test$type, test$predictedtype))
test$predictedtype <- as.factor(test$predictedtype)
table <- data.frame(confusionMatrix(test$type, test$predictedtype)$table)
print(cm)
plotTable <- table %>%
mutate(goodbad = ifelse(table$Prediction == table$Reference, "Good", "Bad")) %>%
group_by(Reference) %>%
mutate(prop = Freq/sum(Freq))
confusionMatrix <- ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 25, size = 8) +
scale_fill_manual(name = " ", values = c(Good = "#F0FF00", Bad = "#34495E")) +
scale_alpha(name = " ") +
theme_classic() +
xlim(rev(levels(table$Reference))) +
scale_y_discrete(name = "Predicted", limits = c("1","0")) +
scale_x_discrete(name = "Actual", position = "top") +
#theme(legend.position = " ") +
theme(text=element_text(size=25,  family="sans")) +
ggtitle("Confusion Matrix") +
theme(plot.title = element_text(size = 25, family="sans", face = "bold"))
confusionMatrix
ROC <- roc(test$type,prob)
plot(ROC, col = "#fd634b", family = "sans", cex = 2, main = "CART Model ROC Curve
AUC = 0.8474")
plot(ROC, col = "#fd634b", family = "sans", cex = 3, main = "CART Model ROC Curve
AUC = 0.8474")
auc(ROC)
is_predictedtype <- predict(type,newdata=train,type='class')
misClassError <- mean(is_predictedtype != train$type)
print(paste('Train-set Accuracy =',1-misClassError))
misClassError <- mean(test$predictedtype != test$type)
print(paste('Test-set Accuracy =',1-misClassError))
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(ggplot2)
library(tidyverse)
library(yardstick)
library(tidymodels)
library(discrim)
library(caret)
library(Hmisc)
library(patchwork)
library(naivebayes)
library(kknn)
library(rpart)
library(rpart.plot)
library(pROC)
data <- readRDS("C:/Users/Javiera/Desktop/RAMOS 2021/Minería/proyectos_mineria/Proyecto_3/endurance.rds")
data_copy1 <- data
head(data)
summary(data)
str(data)
head(unique(data[c("type")]))
head(unique(data[c("records")]))
unique(data[c("device_name")])
unique(data[c("has_heartrate")])
data$type <- mapvalues(data$type, from=c('Ride','EBikeRide'), to=c(0,0))
data$type <- mapvalues(data$type, from=c('Run','Walk', 'Hike'), to=c(1,1,1))
data$type <- as.factor(data$type)
str(data)
data[, c(6:9,13)] <- sapply(data[, c(6:9,13)], as.numeric)
data$start_date_local <- as.numeric(data$start_date_local)
data$device_name <- NULL
describe(data)
data$id <- NULL
data$athlete <- NULL
data$records <- NULL
data$has_heartrate <-
data$start_date_local <- NULL
#data$elev <- as.numeric(as.numeric(data$elev_high) - as.numeric(data$elev_low))
data$elev_high <- NULL
data$elev_low <- NULL
out_distance <- filter(data, type == 0)
boxplot(out_distance$distance, horizontal = TRUE)
out_distance2 <- filter(data, type == 1)
boxplot(out_distance2$distance, horizontal = TRUE)
out_avspeed <- filter(data, type == 0)
boxplot(as.numeric(out_avspeed$average_speed), horizontal = TRUE)
out_avspeed2 <- filter(data, type == 1)
boxplot(as.numeric(out_avspeed2$average_speed), horizontal = TRUE)
#Como en mi notebook los modelos no corrian por la cantidad de datos, tuve que disminuirla
set.seed(123)
data_sample <- sample_n(data, 150000)
#data_sample2 <-data_sample[!(data_sample$type== 0 | data_sample$type== 1),]
data_split <- initial_split(data_sample, prop = 0.8)
train <- training(data_split)
test <- testing(data_split)
test$pred_0 <- NULL
str(train)
receta <-
recipe(type ~ ., data = train)
receta
modelo_trees <-
decision_tree(tree_depth = 5, min_n = 10) %>%
set_engine("rpart") %>%
set_mode("classification")
modelo_trees
library(tibble)
library(pROC)
fit_mod <- function(mod){
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train)
model_pred <-
predict(modelo_fit, test, type = "prob") %>%
bind_cols(test)
return(model_pred
%>%
roc_auc(truth = type, .pred_0))
}
fit_mod(modelo_trees)
library(naivebayes)
modelo_nb <-
naive_Bayes(smoothness = .8) %>%
set_engine("naivebayes")
fit_mod(modelo_nb)
#library(kknn)
#modelo_knn <-
# nearest_neighbor(neighbors = 6) %>%
#set_engine("kknn") %>%
#set_mode("classification")
#fit_mod(modelo_knn)
modelo_rl <-
logistic_reg() %>%
set_engine("glm")
fit_mod(modelo_rl)
library(rpart.plot)
type <- rpart(type~., data = train, method = "class")
rpart.plot(type)
library(rpart.plot)
pred_type <- predict(type, newdata = test, type = "class")
pred_type %>% as.data.frame() %>% head()
pred_type %>% as.data.frame() %>% tail()
test$predictedtype <- pred_type
pred_type_roc <- predict(type, newdata = test, type = "prob")
pred_type_roc %>% as.data.frame() %>% head()
pred_type_roc <- pred_type_roc %>% as.data.frame()
prob <- pred_type_roc$"1"
cm <- confusionMatrix(table(test$type, test$predictedtype))
test$predictedtype <- as.factor(test$predictedtype)
table <- data.frame(confusionMatrix(test$type, test$predictedtype)$table)
print(cm)
plotTable <- table %>%
mutate(goodbad = ifelse(table$Prediction == table$Reference, "Good", "Bad")) %>%
group_by(Reference) %>%
mutate(prop = Freq/sum(Freq))
confusionMatrix <- ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 25, size = 8) +
scale_fill_manual(name = " ", values = c(Good = "#F0FF00", Bad = "#34495E")) +
scale_alpha(name = " ") +
theme_classic() +
xlim(rev(levels(table$Reference))) +
scale_y_discrete(name = "Predicted", limits = c("1","0")) +
scale_x_discrete(name = "Actual", position = "top") +
#theme(legend.position = " ") +
theme(text=element_text(size=25,  family="sans")) +
ggtitle("Confusion Matrix") +
theme(plot.title = element_text(size = 25, family="sans", face = "bold"))
confusionMatrix
ROC <- roc(test$type,prob)
plot(ROC, col = "#fd634b", family = "sans", cex = 2, main = "CART Model ROC Curve
AUC = 0.92")
auc(ROC)
is_predictedtype <- predict(type,newdata=train,type='class')
misClassError <- mean(is_predictedtype != train$type)
print(paste('Train-set Accuracy =',1-misClassError))
misClassError <- mean(test$predictedtype != test$type)
print(paste('Test-set Accuracy =',1-misClassError))
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(ggplot2)
library(tidyverse)
library(yardstick)
library(tidymodels)
library(discrim)
library(caret)
library(Hmisc)
library(patchwork)
library(naivebayes)
library(kknn)
library(rpart)
library(rpart.plot)
library(pROC)
data <- readRDS("C:/Users/Javiera/Desktop/RAMOS 2021/Minería/proyectos_mineria/Proyecto_3/endurance.rds")
data_copy1 <- data
head(data)
summary(data)
str(data)
head(unique(data[c("type")]))
head(unique(data[c("records")]))
unique(data[c("device_name")])
unique(data[c("has_heartrate")])
data$type <- mapvalues(data$type, from=c('Ride','EBikeRide'), to=c(0,0))
data$type <- mapvalues(data$type, from=c('Run','Walk', 'Hike'), to=c(1,1,1))
data$type <- as.factor(data$type)
str(data)
data[, c(6:9,13)] <- sapply(data[, c(6:9,13)], as.numeric)
data$start_date_local <- as.numeric(data$start_date_local)
data$device_name <- NULL
describe(data)
data$id <- NULL
data$athlete <- NULL
data$records <- NULL
data$has_heartrate <-
data$start_date_local <- NULL
#data$elev <- as.numeric(as.numeric(data$elev_high) - as.numeric(data$elev_low))
data$elev_high <- NULL
data$elev_low <- NULL
out_distance <- filter(data, type == 0)
boxplot(out_distance$distance, horizontal = TRUE)
out_distance2 <- filter(data, type == 1)
boxplot(out_distance2$distance, horizontal = TRUE)
out_avspeed <- filter(data, type == 0)
boxplot(as.numeric(out_avspeed$average_speed), horizontal = TRUE)
out_avspeed2 <- filter(data, type == 1)
boxplot(as.numeric(out_avspeed2$average_speed), horizontal = TRUE)
#Como en mi notebook los modelos no corrian por la cantidad de datos, tuve que disminuirla
set.seed(123)
data_sample <- sample_n(data, 10000)
#data_sample2 <-data_sample[!(data_sample$type== 0 | data_sample$type== 1),]
data_split <- initial_split(data_sample, prop = 0.8)
train <- training(data_split)
test <- testing(data_split)
test$pred_0 <- NULL
str(train)
receta <-
recipe(type ~ ., data = train)
receta
modelo_trees <-
decision_tree(tree_depth = 5, min_n = 10) %>%
set_engine("rpart") %>%
set_mode("classification")
modelo_trees
library(tibble)
library(pROC)
fit_mod <- function(mod){
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train)
model_pred <-
predict(modelo_fit, test, type = "prob") %>%
bind_cols(test)
return(model_pred
%>%
roc_auc(truth = type, .pred_0))
}
fit_mod(modelo_trees)
library(naivebayes)
modelo_nb <-
naive_Bayes(smoothness = .8) %>%
set_engine("naivebayes")
fit_mod(modelo_nb)
#library(kknn)
#modelo_knn <-
# nearest_neighbor(neighbors = 6) %>%
#set_engine("kknn") %>%
#set_mode("classification")
#fit_mod(modelo_knn)
modelo_rl <-
logistic_reg() %>%
set_engine("glm")
fit_mod(modelo_rl)
library(rpart.plot)
type <- rpart(type~., data = train, method = "class")
rpart.plot(type)
library(rpart.plot)
pred_type <- predict(type, newdata = test, type = "class")
pred_type %>% as.data.frame() %>% head()
pred_type %>% as.data.frame() %>% tail()
test$predictedtype <- pred_type
pred_type_roc <- predict(type, newdata = test, type = "prob")
pred_type_roc %>% as.data.frame() %>% head()
pred_type_roc <- pred_type_roc %>% as.data.frame()
prob <- pred_type_roc$"1"
cm <- confusionMatrix(table(test$type, test$predictedtype))
test$predictedtype <- as.factor(test$predictedtype)
table <- data.frame(confusionMatrix(test$type, test$predictedtype)$table)
print(cm)
plotTable <- table %>%
mutate(goodbad = ifelse(table$Prediction == table$Reference, "Good", "Bad")) %>%
group_by(Reference) %>%
mutate(prop = Freq/sum(Freq))
confusionMatrix <- ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 25, size = 8) +
scale_fill_manual(name = " ", values = c(Good = "#F0FF00", Bad = "#34495E")) +
scale_alpha(name = " ") +
theme_classic() +
xlim(rev(levels(table$Reference))) +
scale_y_discrete(name = "Predicted", limits = c("1","0")) +
scale_x_discrete(name = "Actual", position = "top") +
#theme(legend.position = " ") +
theme(text=element_text(size=25,  family="sans")) +
ggtitle("Confusion Matrix") +
theme(plot.title = element_text(size = 25, family="sans", face = "bold"))
confusionMatrix
ROC <- roc(test$type,prob)
plot(ROC, col = "#fd634b", family = "sans", cex = 2, main = "CART Model ROC Curve
AUC = 0.92")
auc(ROC)
is_predictedtype <- predict(type,newdata=train,type='class')
misClassError <- mean(is_predictedtype != train$type)
print(paste('Train-set Accuracy =',1-misClassError))
misClassError <- mean(test$predictedtype != test$type)
print(paste('Test-set Accuracy =',1-misClassError))
